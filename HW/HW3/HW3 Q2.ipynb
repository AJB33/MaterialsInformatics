{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Hyperparameter Tuning\n",
    "\n",
    "In HW 2 we used grid and random search to find the best hyperparameters for our models. However, these methods are often considered inefficient (as many of you experienced first hand)! In this assingment we will leverage bayesian optimization to perform this task quicker and hopefully more effectively. We will leverage a popular fine tuning library called `optuna` to accomplish this. Thankfully there is a nice blog post on how to do this to help you get started. You can find it here: [optuna tutorial](https://medium.com/@becaye-balde/bayesian-sorcery-for-hyperparameter-optimization-using-optuna-1ee4517e89a). \n",
    "\n",
    "Additionally, you can head over to their website to see some additional examples: [https://optuna.org/#code_examples](https://optuna.org/#code_examples)\n",
    "\n",
    "For this assignment use `optuna` to optimize the hyperparameters of a random forest model to predict the heat capacity dataset from HW 2. Follow the same splitting procedure to ensure that materials aren't mixed between the training and testing sets. Perform the optimization for 10 trials and report the best hyperparameters and the R^2 and MAE on the training and testing sets. How does this compare to your results from HW 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Input Data: 100%|██████████| 3589/3589 [00:00<00:00, 8715.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFeaturizing Compositions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Features...: 100%|██████████| 3589/3589 [00:01<00:00, 3459.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating Pandas Objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Input Data: 100%|██████████| 981/981 [00:00<00:00, 4626.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFeaturizing Compositions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Features...: 100%|██████████| 981/981 [00:00<00:00, 2434.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating Pandas Objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-30 14:59:57,377] A new study created in memory with name: no-name-5aa6d6f4-faca-4be8-bae3-9ed5eeaa2493\n",
      "[I 2024-03-30 15:00:24,922] Trial 0 finished with value: 0.8908657373826957 and parameters: {'n_estimators': 9, 'max_depth': 47.20814838990367}. Best is trial 0 with value: 0.8908657373826957.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the r2 score is  0.8908657373826957\n",
      "the mean absolute error is  17.117364059727414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-30 15:00:48,437] Trial 1 finished with value: 0.8542525691138293 and parameters: {'n_estimators': 8, 'max_depth': 41.760307949273766}. Best is trial 0 with value: 0.8908657373826957.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the r2 score is  0.8542525691138293\n",
      "the mean absolute error is  19.868235580190284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-30 15:01:14,691] Trial 2 finished with value: 0.8754114708717682 and parameters: {'n_estimators': 9, 'max_depth': 19.448901376366848}. Best is trial 0 with value: 0.8908657373826957.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the r2 score is  0.8754114708717682\n",
      "the mean absolute error is  17.329355103385684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-30 15:01:23,347] Trial 3 finished with value: 0.8759496101370315 and parameters: {'n_estimators': 3, 'max_depth': 32.31455186496834}. Best is trial 0 with value: 0.8908657373826957.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the r2 score is  0.8759496101370315\n",
      "the mean absolute error is  18.06474606410692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-30 15:01:38,022] Trial 4 finished with value: 0.8895679392747871 and parameters: {'n_estimators': 5, 'max_depth': 43.157518805187784}. Best is trial 0 with value: 0.8908657373826957.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the r2 score is  0.8895679392747871\n",
      "the mean absolute error is  17.541938443764867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-30 15:01:55,394] Trial 5 finished with value: 0.8696917959392256 and parameters: {'n_estimators': 6, 'max_depth': 30.769134625792002}. Best is trial 0 with value: 0.8908657373826957.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the r2 score is  0.8696917959392256\n",
      "the mean absolute error is  18.350541986634955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-30 15:02:15,696] Trial 6 finished with value: 0.8585397547415514 and parameters: {'n_estimators': 7, 'max_depth': 45.79819782781949}. Best is trial 0 with value: 0.8908657373826957.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the r2 score is  0.8585397547415514\n",
      "the mean absolute error is  19.20986745789039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-30 15:02:46,438] Trial 7 finished with value: 0.8899922476628883 and parameters: {'n_estimators': 10, 'max_depth': 48.972537839473596}. Best is trial 0 with value: 0.8908657373826957.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the r2 score is  0.8899922476628883\n",
      "the mean absolute error is  17.12756019367992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-30 15:03:01,423] Trial 8 finished with value: 0.861280085822574 and parameters: {'n_estimators': 6, 'max_depth': 12.672700912303323}. Best is trial 0 with value: 0.8908657373826957.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the r2 score is  0.861280085822574\n",
      "the mean absolute error is  18.148083711124205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-30 15:03:17,715] Trial 9 finished with value: 0.8808345560594902 and parameters: {'n_estimators': 6, 'max_depth': 14.762518519487127}. Best is trial 0 with value: 0.8908657373826957.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the r2 score is  0.8808345560594902\n",
      "the mean absolute error is  17.762772274999808\n",
      "Accuracy: 0.8908657373826957\n",
      "Best hyperparameters: {'n_estimators': 9, 'max_depth': 47.20814838990367}\n"
     ]
    }
   ],
   "source": [
    "#your code goes here\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from CBFV import composition\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Define a search space for the hyperparameters `n_estimators` and `max_depth`\n",
    "    of a random forest model, then train and evaluate it using cross validation.\n",
    "    \"\"\"\n",
    "\n",
    "    # function from https://medium.com/@becaye-balde/bayesian-sorcery-for-hyperparameter-optimization-using-optuna-1ee4517e89a\n",
    "  \n",
    "    n_estimators = trial.suggest_int('n_estimators', 1, 10)\n",
    "    max_depth = int(trial.suggest_float('max_depth', 10, 50, log=True))\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    \n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print('the r2 score is ',r2)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print('the mean absolute error is ',mae)\n",
    "\n",
    "    return r2\n",
    "\n",
    "\n",
    "# data is in a csv file stored in c drive to avoid space in my username\n",
    "filename = 'C:\\cp_data_demo.csv'\n",
    "\n",
    "# read the data from the csv file into a pandas dataframe\n",
    "df=pd.read_csv(filename)\n",
    "# change the column names to the column names required by the featurizer\n",
    "rename_dict = {'CONDITION: Temperature (K)':'Temperature', 'PROPERTY: Heat Capacity (J/mol K)':'target', 'FORMULA':'formula'}\n",
    "df = df.rename(columns=rename_dict)\n",
    "# drop NaN values\n",
    "df = df.dropna()\n",
    "# reset the index after dropping values\n",
    "df = df.reset_index(drop=True)\n",
    "# find the number of unique values in the dataset\n",
    "nunique=df.nunique()\n",
    "# get the values of the unique data\n",
    "unique_vals=pd.Series({c: df[c].unique() for c in df})\n",
    "# define groups for the k-fold as the unique formula names\n",
    "groups = df['formula'].unique()\n",
    "\n",
    "# split data into training and testing sets by splitting the group names\n",
    "train_groups,test_groups = train_test_split(groups, test_size=0.2, random_state=42)\n",
    "train_df = df[df['formula'].isin(train_groups)]\n",
    "test_df = df[df['formula'].isin(test_groups)]\n",
    "\n",
    "# Featurize the data \n",
    "X_train_feats_unscaled, y_train, formulae_train, skipped_train = composition.generate_features(train_df, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)\n",
    "X_test_feats_unscaled, y_test, formulae_train, skipped_train = composition.generate_features(test_df, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_feats_unscaled)\n",
    "X_test = scaler.transform(X_test_feats_unscaled)\n",
    "\n",
    "# Normalize the data\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n",
    "\n",
    "# create a study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# get the best trial\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge ended with R2 = 0.86 and XGBoost with R2 = 0.9. The optimized Random Forest Regressor performed with an R2 value of 0.89."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MatInformatics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
